![[Pasted image 20240406165147.png]]

# Q 1 怎么评估模型并选择模型？
- 训练目的：训练模型的目的是为了在新样本有较好的预测效果
- 泛化能力：训练模型适用于新样本的能力
- 泛化误差：新样本在模型上的误差
# Q 怎么划分数据集
![[Pasted image 20240406165440.png]]

### **交叉验证**

在样本量足够大的理想情况下，应当把数据集分割为三部分：**训练集(training set)**、**验证集(validation set)**，**测试集(testing set)**，分别用于模型训练、模型选择和模型评估，用于评估模型泛化能力的测试集只出现在最后的模型评估环节。但很多时候数据不够充足，这种时候可以取消验证集，采用**交叉验证**方法，通过反复划分训练集和测试集来避免用同一批数据训练和评估一个模型，相当于将验证集和测试集合二为一了，下面具体进行介绍：

**交叉验证(cross validation)**：指的是对有限的数据集进行随机划分，利用分割后的部分组成训练集和测试集，进而重复进行模型的训练、选择和评估。常用的交叉验证法有三种：

- **简单交叉验证/留出法(hold-out)**：将数据集按一定比例随机分为两部分：训练集和测试集，分别在其上训练和测试所有备选模型，选出测试结果最好的，这相当于用模型评估代替了模型选择，直接砍掉验证集来增加其余两个集合的样本量，简单粗暴；
- **K 折交叉验证(k-fold cross validation)**：将数据集随机划分为 $K$ 个大小相同或基本相同的子集，分别把每一个子集作为测试集，其余 ($K$ −1) 个子集作为训练集，就得到 $K$ 组不同的训练、测试集，在这 $K$ 组训练、测试集上训练并测试每一种模型，选择平均测试误差最小的模型；有时为了避免单次随机划分的特殊性，还会进行多次随机划分，将多个交叉验证的结果再进行一次平均；
- **留一交叉验证(leave-one-out cross validation)**：K 折交叉验证的特例，将 K 取为样本量 N，也即把每个样本单独作为测试集，其余样本作为训练集。这种方法的计算量较大，一般仅用于数据稀少的情况。

当样本量实在过小时，可以考虑采用有放回抽样，抽取次数和原数据集样本量相等，形成一个新的样本作为训练集，而将未被抽到过的样本全体作为测试集，这种在样本量较小的情况下构造样本的想法来源于统计学中的**自助法(bootstrapping)**。
![[Pasted image 20240406171030.png]]
# 如何调模型参数
![[Pasted image 20240406170330.png]]
