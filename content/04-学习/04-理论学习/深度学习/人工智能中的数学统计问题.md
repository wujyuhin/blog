# 人工智能中的数学与统计问题
人工智能领域中的数学问题和统计问题与一般数学或统计学研究的问题有所不同，以下是对人工智能领域中特定的数学问题和统计问题及其解决方法与相关理论的概括：

**数学问题与解决方法**

1. **大规模优化问题**：
   - **问题描述**：训练大型神经网络时，需要在高维参数空间中寻找全局或局部最优解，这是一个大规模非凸优化问题，且存在梯度稀疏、消失、爆炸等问题。
   - **解决方法**：除了常规的梯度下降法及其变种，还引入了动量项（如 Adam、RMSprop）、正则化技术（如 L 1、L 2 正则化）、批量归一化、权重初始化策略（如 Xavier、He 初始化）、早停等技术来改善收敛性和泛化能力。此外，研究者还探索二阶优化方法、元学习、自适应学习率调整等高级优化技术。

2. **深度网络的数学结构与性质**：
   - **问题描述**：理解和分析深度神经网络的数学特性，如深度、宽度、非线性激活函数的选择对模型性能的影响，以及网络的泛化能力、表达能力、稳定性等。
   - **解决方法**：运用函数逼近论、微分几何、复分析等工具研究网络的容量、深度与宽度的关系，以及激活函数的选择对网络动态行为的影响。研究者还开发了深度网络的谱理论，探讨网络的谱属性与模型性能之间的联系。

3. **图神经网络的数学基础**：
   - **问题描述**：在处理图结构数据时，需要设计能够捕捉节点间关系的数学模型，并解决图信号处理、消息传递、注意力机制等问题。
   - **解决方法**：借鉴图论、信号处理、矩阵论等领域的理论，开发基于拉普拉斯矩阵、谱图理论、随机游走、图卷积等方法的图神经网络模型。设计有效的消息传递机制和自适应注意力机制来增强模型对图结构的捕获能力。

4. **概率图模型的推理与学习**：
   - **问题描述**：在概率图模型（如马尔可夫随机场、条件随机场、贝叶斯网络）中，如何有效地进行概率推理（如边缘概率计算、条件概率查询、模式识别）和模型参数学习。
   - **解决方法**：运用信念传播、变量消除、 Junction Tree 算法等进行精确或近似推理，使用最大似然估计、最大后验估计、EM 算法、变分推断等方法进行参数学习。近年来，研究者还探索基于深度学习的近似推理方法，如神经信念传播、深度能量模型等。

**统计问题与解决方法**
1. 深度学习和机器学习中的数据问题
	- 问题描述
		1. 数据量不足
		2. **数据不平衡**：当不同类别的样本数量差异显著时，模型可能偏向于多数类，忽略少数类，导致预测偏差。例如，在疾病诊断中，若健康样本远多于病患样本，模型可能过于乐观，低估患病风险。
		3. 噪声数据、缺失数据
		4. **数据偏见**：数据收集过程中可能无意中引入偏见，如采样偏差、文化偏见等，使得模型学习到的规律反映这些偏见，而非真实世界的普遍规律。
		5. **特征选择与工程**：选择哪些特征以及如何转换原始数据为更有意义的特征，对模型性能至关重要。不恰当的特征选择可能导致模型复杂度过高或过低。
		6. **维度灾难**：在高维空间中，数据稀疏且距离度量变得困难，这称为“维度灾难”。深度学习模型虽能较好处理高维数据，但仍然需要有效的特征降维和正则化技术来避免过拟合。
		7. **数据分布变化**：训练数据和测试数据或实际应用中的数据分布不一致，称为域偏移，这会影响模型的泛化能力。
	- 解决方法：数据增强、欠采样/过采样技术、特征选择、数据合成、迁移学习、域适应技术以及对模型进行正则化等策略。

2. **大数据下的统计推断（大数据）**：
   - **问题描述**：面对海量数据，传统的统计推断方法可能无法有效处理，需要发展适合大数据特性的统计推断框架。（但一般场景下没有所谓的海量数据）
   - **解决方法**：发展分布式统计推断算法（如 MapReduce 框架下的统计计算），使用在线学习、增量学习、 mini-batch 梯度下降等方法应对大数据流。此外，还研究大样本理论在大数据环境下的适用性，以及如何利用数据的结构化、稀疏性等特点来提高推断效率。

3. **非参数与半参数模型（复杂数据分布、未知数据分布）**：
   - **问题描述**：在许多 AI 应用中，数据分布可能非常复杂，难以用参数模型准确描述，需要考虑非参数或半参数模型。这在处理复杂数据模式和未知数据分布时尤为有用。
	   - 模式识别分类问题，非参方法不依赖数据分布，因此可以处理高维、非线性特征空间中的复杂模式
	   - 密度估计问题：未知复杂数据分布，需要估计数据的概率密度函数，这对聚类分析、异常值检测有用
	   - 回归分析、时序分析问题：处理复杂周期性、趋势、非线性动力学的时序数据，如自回归条件密度回归
   - **解决方法**：应用核方法（如支持向量机、核密度估计）、决策树、随机森林、神经网络等非参数或半参数模型，这些模型具有较强的灵活性和适应性。对于半参数模型，结合参数模型的解析性与非参数模型的灵活性，如广义 additive models (GAMs)。

4. **人工智能中的因果推断**（数据偏见）：
   - **问题描述**：在人工智能领域，因果推断问题是指利用数据来识别变量间的因果关系，而不仅仅需要关联分析或相关性分析，以实现可靠的决策支持。下面是人工智能中存在的因果推断问题：
	   - 策略评估：推荐算法中因果推断能够评估不同策略的效果、哪些因素真实驱动结果变化。
	   - 数据偏见问题消除：数据可能存在社会、文化等的偏见，而机器学习会学习并放大这些偏见，导致不公平的决策。例如一些学校在不同竞赛中筛选学生是存在性别偏见，或者教育文化环境导致不同性别的竞赛倾向不同，即使竞赛能力与性别关系没那么大。所以可能导致预测模型中学习了这些偏见。
	   - 解释性和可追溯性：深度学习中存在不可解释性问题，因果模型提供了一种解释机器学习预测和决策的框架。
	   - 强人工智能：人工智能算法缺少因果推断能力，需要从经验中学习底层逻辑做出合理的因果推理。需要融入因果推断。
   - **解决方法**：构建因果图、识别调整混淆变量（倾向得分匹配、逆概率加权、分层分析、双重差分、工具变量等）、因果效应分析（潜在结果框架、结构方程等）等工具进行因果关系建模与推断，还有基于机器学习的因果推断方法，如因果森林、神经因果推断等。这些方法帮助发现数据中的隐含偏见，或者不正确的因果关系。

5. **分类与聚类**：
   - **问题描述**：人工智能中，将观测数据分配到预定义类别或自动形成无监督的类别结构。
   - **解决方法**：使用决策树、随机森林、支持向量机、K 近邻算法、朴素贝叶斯分类器等进行分类，采用 K-means、谱聚类、DBSCAN 等方法进行聚类。

6. **降维与特征提取（维度灾难）**：
   - **问题描述**：人工智能和大数据中，需要减少数据维度以简化模型、降低计算复杂度、揭示潜在结构。
   - **解决方法**：应用主成分分析（PCA）、独立成分分析（ICA）、局部线性嵌入（LLE）、t-SNE 等降维技术，以及傅立叶变换、小波分析、深度学习中的卷积层等特征提取方法。


**相关理论**

1. **机器学习理论**：
   - **泛化理论**：研究模型在训练数据上的表现如何推广到未见过的数据，包括 VC 维理论、Rademacher 复杂度、 PAC 学习理论等，为模型选择、正则化、模型复杂度控制提供理论依据。
	   - **VC 维理论**：描述学习器的复杂度与模型泛化能力的关系，为模型选择和正则化提供理论依据。
	   - **PAC 学习理论**：同等条件下，模型越复杂，泛化误差越大。样本数量越大，模型泛化误差越小，模型越复杂越需要吃样本。
		   - 在 $\epsilon$ 误差参数内， $\delta$ 与测失败概率内，在合理的样本量下，满足经验误差小于误差内的概率大于一定界限，说明能够辨识概念类 C，就是 PAC 可学习
		   - 若算法运行复杂度在多项式内，就是高效 PAC 可学习的，算法被称为 PAC 学习算法
		   - ![[Pasted image 20240427211735.png]]
   - **深度学习理论**：探讨深度网络的表示能力、泛化能力、优化难题等，如深度学习的表示定理、神经网络的宽度与深度的关系、神经网络的通用逼近性质、深度学习的双谷现象、过参数化网络的泛化能力等。
	   - 双谷现象揭示了一个更为复杂的情形：当模型复杂度继续增加，经过一个过拟合的高峰期后，测试误差竟然会再次下降，形成第二个谷底。这意味着非常大的模型（有时被称为“过参数化”模型）在某些情况下能够展现出比中小规模模型更好的泛化能力。这一发现挑战了以往对模型复杂度与泛化性能之间简单关系的理解。
   - **鲁棒性理论**（在统计学和数据分析中是一个重要的概念。）
	   - 概念：指的是某个统计方法或模型对于异常值或偏离数据集正常分布的情况的敏感程度。
		   - 一个鲁棒性较好的方法能够在存在异常值或数据分布不符合假设的情况下依然给出可靠的结果，而不会被极端值影响太大。
		   - 鲁棒性方法旨在降低异常值对整体结果的影响，使得分析更加稳健和可靠。
		   - 鲁棒性的核心思想是抵抗异常值的干扰，总结如下：位置测度选择（中位数代替均值）、离散程度度量（MAD 绝对离差中位数）、异常值检测、非参数方法（不假设数据分布，直接利用数据排序和秩）、重抽样技术（自助法）
	   - 神经网络鲁棒性 (https://arxiv.org/abs/2102.11935)
		- 论文介绍[硬核！IBM对「神经网络鲁棒性」的理论分析-CSDN博客](https://blog.csdn.net/moxibingdao/article/details/114812046)
		- 截取：定理分别给出了第 i 个类别和第 j 个类别在联合扰动中单层扰动和全层扰动这两种情况下的预测标签概率差值的上界。有坚实的理论做依靠使得作者能够提出基于理论推导得出的具有鲁棒性的损失函数。

2. **强化学习理论**：
   - **数学问题：**
	   - 优化问题：策略优化，通常涉及到在策略空间中进行优化，以最大化累积奖励。这属于连续或离散优化问题，可能需要解决非凸、高维度、非线性等问题。
	   - **马尔可夫决策过程问题(MDP)**：
		   - MDP 模型的建立与分析，包括状态空间、动作空间、转移概率和奖励函数的定义，以及 MDP 的结构性质研究。
		   - **动态规划与贝尔曼方程**：**值函数迭代与策略迭代**：利用贝尔曼期望方程和贝尔曼最优方程求解**状态价值函数**和**动作价值函数**，涉及迭代计算和收敛性分析。
		   - 其他强化学习的迭代策略：**Q-learning**与**SARSA**：两种经典的模型无关的强化学习算法，用于学习最优动作价值函数。
	   - **蒙特卡洛方法**：基于大量采样进行无模型强化学习，适用于复杂环境下的策略评估与优化。
   - **统计问题**：
	   - 估计问题：强化学习基于有限的样本来估计长期回报、状态转移概率等，因此涉及统计学习理论，如样本复杂度分析、置信区间估计等
	   - 噪声问题：强化学习算法必须处理观测噪声和模型不确定性，这需要利用贝叶斯方法（对噪声进行建模假设分布，在动态环境中学习适应噪声的参数分布）、置信区间估计等统计工具。
	   - 因果推断：理解动作奖励的因果关系对学习策略至关重要，需要应用因果推断方法技术
	   - 时间序列：强化学习中处理的往往是时间序列模型，需要处理序列相关性、趋势、周期性等
	   - 生成模型：在一些强化学习场景下，需要建模状态转移和奖励分布，涉及统计中的密度估计和生成模型构建

总结来说，人工智能领域中的数学问题和统计问题主要围绕优化、深度网络结构与性质、图神经网络、概率图模型、大数据统计推断、非参数与半参数模型、因果推断等方面展开。

# 李乐老师说的
## 泛化性理论
模型的风险给出一个较小的上确界，或者是不是满足机器学习中的 PAC 条件
## 鲁棒性理论
模型对招生或者对抗样本的表现
数据分布给一个扰动会对模型表现有什么影响
## 模型参数估计
使用什么样的优化算法，更快收敛，避免局部最优
## 强化学习
智能体与环境交互学习最优决策策略
马尔可夫决策过程
值函数
## 数据问题
小样本学习
数据增强，如统计采样的方法做重抽样
## 长序列建模问题
## 流形学习
